# -*- coding: utf-8 -*-
"""timePredML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/wichersq/alarm-predict-ML/blob/master/timePredML.ipynb

The model is a 5 layer fully connected network that takes in the features defined in **list_samp_x** below. It outputs how long before the event the user should start getting ready. It is implemented in Tensorflow. Values in the data are sometimes nan, so the preprocessing code sets these to -1 and defines another column which indicates if the feature was originally nan or not.
"""

import tensorflow as tf
import pandas as pd

# from google.colab import files

FILE_NAME_WITH_TOTAL_DURATION = 'https://raw.githubusercontent.com/wichersq/alarm-predict-ML/master/Data/converted_data_with_totalDuration.csv'

data_df = pd.read_csv(FILE_NAME_WITH_TOTAL_DURATION)

print(data_df.head(10))


def get_open_close_time(df_input_hour, day_in_week):
    open_col = []
    close_col = []
    for n in range(len(day_in_week)):
        day = day_in_week[n]
        col = df_input_hour.iloc[n]
        close_col.append(col[((day * 2) - 2)])
        open_col.append(col[((day * 2) - 1)])
    return close_col, open_col


input_df = data_df.copy()

input_df['Destination'] = data_df['Business Name'] + ', ' + data_df["Destination Address"]

store_hour_df = data_df[['Day1_Close', 'Day1_Open', 'Day2_Close', 'Day2_Open', 'Day3_Close',
                         'Day3_Open', 'Day4_Close', 'Day4_Open', 'Day5_Close', 'Day5_Open',
                         'Day6_Close', 'Day6_Open', 'Day0_Close', 'Day0_Open']]

# Storing NAN value as 0 and available value as 1.
input_df['Close_Time'], input_df['Open_Time'] = get_open_close_time(store_hour_df, data_df['Day of the Week'])
input_df['Does_Reviews_Exist?'] = data_df['Reviews'].notnull().astype(int)
input_df['Does_Rating_Exist?'] = data_df['Rating'].notnull().astype(int)
input_df['Does_Price_Lv_Exist?'] = input_df['Price Level'].notnull().astype(int)
input_df['Does_Walking_Exist?'] = input_df['Walking_Duration'].notnull().astype(int)
input_df['Does_Transit_Exist?'] = input_df['Transit_Duration'].notnull().astype(int)
input_df['Does_Close/Open_Time_Exist?'] = input_df['Open_Time'].notnull().astype(int)

# get rid of nan
input_df = input_df.fillna(-1)


def linear_scale(series):
    min_val = series.min()
    max_val = series.max()
    scale = (max_val - min_val)
    return series.apply(lambda x: ((x / scale)))


input_df['Reviews'] = linear_scale(input_df['Reviews'])

print(input_df.head(10))

train_df = input_df.sample(frac=0.8, random_state=0)
test_df = input_df.drop(train_df.index)


def dumb_model(x):
    """Gets about 3500 error"""
    pred = x[:, 0]
    add = tf.Variable(0.0)
    pred += add
    return pred


def NN_model(x):
    pred = tf.layers.dense(inputs=x, units=100, activation=tf.nn.leaky_relu)
    pred = tf.layers.dense(inputs=pred, units=50, activation=tf.nn.leaky_relu)
    pred = tf.layers.dense(inputs=pred, units=10, activation=tf.nn.leaky_relu)
    pred = tf.layers.dense(inputs=pred, units=5, activation=tf.nn.leaky_relu)
    pred = tf.layers.dense(inputs=pred, units=1)
    return pred


tf.reset_default_graph()

list_samp_x = ['Driving_Duration', 'Price Level', 'Does_Price_Lv_Exist?', 'Rating', 'Does_Rating_Exist?', 'Reviews',
               'Does_Reviews_Exist?']
x = tf.placeholder(shape=(None, len(list_samp_x)), dtype=tf.float32)
y_ = tf.placeholder(shape=(None, 1), dtype=tf.float32)
pred = NN_model(x)

loss = tf.square(y_ - pred)
error = tf.abs(y_ - pred)
loss = tf.reduce_mean(loss)
error = tf.reduce_mean(error)

opt = tf.train.AdamOptimizer(.0003).minimize(loss)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
loss_vals = []

for i in range(60000):
    batch = train_df.sample(100)
    samp_x = batch.as_matrix(list_samp_x)
    samp_y = batch.as_matrix(['Total_Driving'])
    _, loss_val, error_val = sess.run([opt, loss, error], feed_dict={x: samp_x, y_: samp_y})
    if i % 6000 == 0:
        print("loss", loss_val, "\n error_sec", error_val)

        batch = test_df
        samp_x = batch.as_matrix(list_samp_x)
        samp_y = batch.as_matrix(['Total_Driving'])
        loss_val, error_val = sess.run([loss, error], feed_dict={x: samp_x, y_: samp_y})
        print("testing_loss", loss_val, "\n testing_error_sec", error_val)

# With all features
# error 171.95436

# without price level
# error 187.73192

# without review
# error 258.79532
